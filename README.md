# ğŸ“š Document Theme Identifier Chatbot

An AI-powered chatbot that allows users to upload documents (PDFs/images), ask questions, and get **theme-based summaries** with **sentence-level citations**.

âœ¨ **Features Implemented:**

- ğŸ§  LLM-powered theme summary (Mistral-7B via HuggingFace)
- ğŸ” Sentence-level citations (not just page-level)
- ğŸ“„ PDF/image document upload
- ğŸŒ Modern UI with loading indicators, clean layout

---

## ğŸ§© Tech Stack

| Layer      | Tech Used                        |
|------------|----------------------------------|
| Frontend   | React.js                         |
| Backend    | FastAPI                          |
| Vector DB  | ChromaDB                         |
| Embedding  | SentenceTransformers (`MiniLM`)  |
| OCR Engine | PyMuPDF + Tesseract              |
| LLM Model  | HuggingFace Inference API        |

---

## ğŸ“ Project Structure

```
document-theme-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routers/       # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/      # OCR, vector search, LLM logic
â”‚   â”‚   â”œâ”€â”€ config.py      # Env setup and constants
â”‚   â”‚   â””â”€â”€ main.py        # App entry
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js         # Main UI component
â”‚   â”‚   â”œâ”€â”€ App.css        # Styling
â”‚   â”‚   â””â”€â”€ index.js       # Entry point
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md              # You're here!
```

---

## ğŸš€ How to Run

### 1. Clone the Project

```bash
git clone https://github.com/ashish739293/chatbot_theme_identifier.git
cd chatbot_theme_identifier
```

---

### 2. Setup: Backend (FastAPI)

#### âœ… Prerequisites

- Python 3.9+
- [Tesseract OCR installed](https://github.com/tesseract-ocr/tesseract)

#### ğŸ“¦ Install dependencies

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### ğŸ—ï¸ Add `.env` file

Create `backend/.env`:

```env
HF_API_TOKEN=your_huggingface_api_key
```

#### â–¶ï¸ Start the FastAPI server

```bash
uvicorn app.main:app --reload
```

---

### 3. Setup: Frontend (React)

#### ğŸ“¦ Install dependencies

```bash
cd frontend
npm install
```

#### â–¶ï¸ Start React app

```bash
npm start
```

App runs at: [http://localhost:3000](http://localhost:3000)

---

## ğŸ’¡ How It Works

1. **Upload Document**  
   PDF or image files are uploaded â†’ text extracted via PyMuPDF or Tesseract OCR.

2. **Text Chunks & Embeddings**  
   Each paragraph/sentence is split into chunks â†’ embedded using `MiniLM`.

3. **Store in Chroma VectorDB**  
   Embeddings + metadata (doc_id, page, sent_idx) are stored in Chroma.

4. **Ask Questions**  
   Questions are embedded â†’ semantic similarity search finds relevant chunks.

5. **LLM Summary**  
   Top N citations are passed into an LLM prompt â†’ generates theme-level summary with references.

6. **UI**  
   React shows:
   - Summary
   - Sentence-level citations
---

## ğŸ§  Backend Code Overview 

### `main.py`

```python
from fastapi import FastAPI
from app.api.routes import router
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Document Theme Chatbot")


# Allow CORS for your frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # frontend dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(router, prefix="/api")

```

### Services

- `ocr_service.py` â€“ extracts text from PDF/image (including scanned)
- `embeddings_service.py` â€“ generates dense vectors using MiniLM
- `vector_db_service.py` â€“ ChromaDB logic for insert/search
- `llm_service.py` â€“ summarizes with HuggingFace LLM
- `pdf_service.py` â€“ file storage, chunking, metadata

---

## ğŸ–¼ï¸ Frontend UI Overview

### `App.js`

- Upload panel
- Ask question input
- Filters (filetype, include/exclude)
- Summary output
- Citation table with clickable modal

### `App.css`

Styled with attractive, clean layout:
- `box` â€“ each panel
- `modal` â€“ citation popups
- `loading` â€“ button state and indicator

---

## ğŸ“¦ Backend Dependencies

### `requirements.txt`

```
fastapi
uvicorn
python-dotenv
sentence-transformers
chromadb
pytesseract
pillow
PyMuPDF
requests
```

---

## ğŸŒ Deployment Notes

- You can Dockerize both frontend and backend separately.
- HuggingFace API requires a free token (for Mistral model).
- For production, use Postgres or Qdrant for vectors instead of local Chroma.

---

## ğŸ Future Enhancements

âœ… Implemented:
- âœ… Sentence-level citations
- âœ… Loading state UI

Coming Soon:
- ğŸ§¾ PDF rendering with `react-pdf`
- ğŸ§­ Map view of document sections
- ğŸ“š Clustered theme extraction

---

## ğŸ¤ Contributions & License

MIT License.  
Feel free to fork and contribute. Credit appreciated.
